{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "imJDkCrIZu-l"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PlGfiF0EutTZ"
   },
   "outputs": [],
   "source": [
    "# Set the path to the dataset\n",
    "data_dir = 'C:/Users/Nikita/Desktop/extra/dataset/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GcO_ywzHZ6eJ"
   },
   "outputs": [],
   "source": [
    "# Set the batch size and input image size for the model\n",
    "batch_size = 32\n",
    "input_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PDZk_-buaOua"
   },
   "outputs": [],
   "source": [
    "# Set the number of classes in the dataset\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jeHqhrcWbrmG"
   },
   "outputs": [],
   "source": [
    "# Set the number of epochs to train the model for\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "H6BvoN9TrXhu"
   },
   "outputs": [],
   "source": [
    "# Set up data augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ypAfsqT5u96Z"
   },
   "outputs": [],
   "source": [
    "# Set up data augmentation for validation data\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zxkR4e4vAGk",
    "outputId": "5b31ea21-2311-4b7e-eda3-75a16a032566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 944 images belonging to 4 classes.\n",
      "Found 944 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators for training and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(data_dir, ''),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(data_dir, ''),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG1cYu4fvDZ9",
    "outputId": "c7946cd9-9218-4704-e8cc-fb2818e43c63"
   },
   "outputs": [],
   "source": [
    "# Load the MobileNetV2 model without the top layers\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "22P7rIuhvggu"
   },
   "outputs": [],
   "source": [
    "# Add a new top layer for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "vImELjoQvjjm"
   },
   "outputs": [],
   "source": [
    "# Create the new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "KS0I8YvivlaW"
   },
   "outputs": [],
   "source": [
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "m8_4QVN6vm2C"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAQzUx4uvo2I",
    "outputId": "f16e8bba-f20a-497f-dc5d-dbd1bddb18f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 56s 2s/step - loss: 1.6562 - accuracy: 0.2807 - val_loss: 1.2703 - val_accuracy: 0.4036\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 54s 2s/step - loss: 1.3126 - accuracy: 0.3898 - val_loss: 1.2029 - val_accuracy: 0.4364\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 53s 2s/step - loss: 1.2722 - accuracy: 0.4195 - val_loss: 1.1375 - val_accuracy: 0.5519\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 53s 2s/step - loss: 1.2079 - accuracy: 0.4619 - val_loss: 1.0751 - val_accuracy: 0.5784\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 52s 2s/step - loss: 1.1743 - accuracy: 0.4788 - val_loss: 1.0094 - val_accuracy: 0.6133\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 54s 2s/step - loss: 1.1388 - accuracy: 0.4968 - val_loss: 1.0154 - val_accuracy: 0.5922\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 54s 2s/step - loss: 1.1359 - accuracy: 0.4873 - val_loss: 0.9554 - val_accuracy: 0.6737\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 54s 2s/step - loss: 1.0884 - accuracy: 0.5487 - val_loss: 0.9032 - val_accuracy: 0.6801\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 57s 2s/step - loss: 1.0494 - accuracy: 0.5328 - val_loss: 0.8608 - val_accuracy: 0.7087\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 55s 2s/step - loss: 1.0295 - accuracy: 0.5614 - val_loss: 0.8606 - val_accuracy: 0.7034\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 57s 2s/step - loss: 1.0114 - accuracy: 0.5689 - val_loss: 0.8256 - val_accuracy: 0.7002\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 55s 2s/step - loss: 0.9800 - accuracy: 0.6112 - val_loss: 0.8084 - val_accuracy: 0.7193\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 55s 2s/step - loss: 0.9760 - accuracy: 0.6006 - val_loss: 0.7694 - val_accuracy: 0.7267\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 54s 2s/step - loss: 0.9346 - accuracy: 0.6282 - val_loss: 0.7222 - val_accuracy: 0.7436\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.9442 - accuracy: 0.5996 - val_loss: 0.7221 - val_accuracy: 0.7648\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 54s 2s/step - loss: 0.9407 - accuracy: 0.5985 - val_loss: 0.7357 - val_accuracy: 0.7479\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.9262 - accuracy: 0.6165 - val_loss: 0.6841 - val_accuracy: 0.7934\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.8695 - accuracy: 0.6324 - val_loss: 0.6454 - val_accuracy: 0.7934\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.8246 - accuracy: 0.6684 - val_loss: 0.6252 - val_accuracy: 0.8114\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.8212 - accuracy: 0.6727 - val_loss: 0.5965 - val_accuracy: 0.8220\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 64s 2s/step - loss: 0.8347 - accuracy: 0.6663 - val_loss: 0.5692 - val_accuracy: 0.8305\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 64s 2s/step - loss: 0.8206 - accuracy: 0.6706 - val_loss: 0.5641 - val_accuracy: 0.8411\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.8244 - accuracy: 0.6716 - val_loss: 0.5434 - val_accuracy: 0.8570\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 53s 2s/step - loss: 0.8002 - accuracy: 0.6780 - val_loss: 0.5531 - val_accuracy: 0.8390\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 54s 2s/step - loss: 0.7673 - accuracy: 0.6928 - val_loss: 0.5078 - val_accuracy: 0.8570\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.7071 - accuracy: 0.7426 - val_loss: 0.4717 - val_accuracy: 0.8633\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 66s 2s/step - loss: 0.7585 - accuracy: 0.6896 - val_loss: 0.4677 - val_accuracy: 0.8824\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 69s 2s/step - loss: 0.6622 - accuracy: 0.7352 - val_loss: 0.4262 - val_accuracy: 0.8951\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 68s 2s/step - loss: 0.7074 - accuracy: 0.7235 - val_loss: 0.4294 - val_accuracy: 0.8972\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 64s 2s/step - loss: 0.6669 - accuracy: 0.7532 - val_loss: 0.4090 - val_accuracy: 0.8898\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.6804 - accuracy: 0.7309 - val_loss: 0.3920 - val_accuracy: 0.9110\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.6599 - accuracy: 0.7352 - val_loss: 0.3724 - val_accuracy: 0.9248\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.6513 - accuracy: 0.7426 - val_loss: 0.3547 - val_accuracy: 0.9110\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 64s 2s/step - loss: 0.6048 - accuracy: 0.7818 - val_loss: 0.3546 - val_accuracy: 0.9248\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.5922 - accuracy: 0.7712 - val_loss: 0.3317 - val_accuracy: 0.9258\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.5991 - accuracy: 0.7775 - val_loss: 0.3281 - val_accuracy: 0.9258\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 55s 2s/step - loss: 0.5762 - accuracy: 0.7797 - val_loss: 0.3118 - val_accuracy: 0.9290\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.5442 - accuracy: 0.7945 - val_loss: 0.2988 - val_accuracy: 0.9417\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 59s 2s/step - loss: 0.5639 - accuracy: 0.7786 - val_loss: 0.3070 - val_accuracy: 0.9237\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.5167 - accuracy: 0.8030 - val_loss: 0.2850 - val_accuracy: 0.9428\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 60s 2s/step - loss: 0.5532 - accuracy: 0.7881 - val_loss: 0.2731 - val_accuracy: 0.9375\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5452 - accuracy: 0.7945 - val_loss: 0.2579 - val_accuracy: 0.9597\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 59s 2s/step - loss: 0.5220 - accuracy: 0.7956 - val_loss: 0.2541 - val_accuracy: 0.9534\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.4867 - accuracy: 0.8157 - val_loss: 0.2373 - val_accuracy: 0.9608\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.4970 - accuracy: 0.8072 - val_loss: 0.2272 - val_accuracy: 0.9619\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 54s 2s/step - loss: 0.4850 - accuracy: 0.8125 - val_loss: 0.2136 - val_accuracy: 0.9597\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4571 - accuracy: 0.8284 - val_loss: 0.2311 - val_accuracy: 0.9513\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 53s 2s/step - loss: 0.4707 - accuracy: 0.8189 - val_loss: 0.2187 - val_accuracy: 0.9597\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 66s 2s/step - loss: 0.4432 - accuracy: 0.8390 - val_loss: 0.1959 - val_accuracy: 0.9619\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.4576 - accuracy: 0.8252 - val_loss: 0.1917 - val_accuracy: 0.9640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2380cc630a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=val_generator,\n",
    "          callbacks=[EarlyStopping(patience=3, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "W9yUR2m4vrEB"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EaWzf_1E0uLe"
   },
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the emotion labels\n",
    "emotion_labels = {0: 'angry', 1: 'happy', 2: 'sad' , 3:'relaxed'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the image from the request\n",
    "    img = request.files['image'].read()\n",
    "\n",
    "    # Preprocess the image\n",
    "    img = image.img_to_array(image.load_img(io.BytesIO(img), target_size=(224, 224))) / 255.\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    pred = model.predict(img)\n",
    "    pred_label = emotion_labels[np.argmax(pred)]\n",
    "\n",
    "    # Return the prediction as JSON\n",
    "    return jsonify({'emotion': pred_label})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
